{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "import utils as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the Fashion MNIST dataset, create a dataloader for it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './fashionMNIST/'\n",
    "\n",
    "# transforms for images\n",
    "transform=transforms.Compose([transforms.ToTensor()])\n",
    "# prepare transforms standard to MNIST\n",
    "mnist_train = FashionMNIST(DATA_DIR, train=True, download=True, transform=transform)\n",
    "dl = DataLoader(mnist_train, batch_size=64, num_workers=utils.get_num_cpus())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the MNIST data on a grid so we can see it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class map from the fashion mnist website https://github.com/zalandoresearch/fashion-mnist\n",
    "classes = {0: 'T-shirt/top',\n",
    "           1: 'Trouser',\n",
    "           2: 'Pullover',\n",
    "           3: 'Dress',\n",
    "           4: 'Coat',\n",
    "           5: 'Sandal',\n",
    "           6: 'Shirt',\n",
    "           7: 'Sneaker',\n",
    "           8: 'Bag',\n",
    "           9: 'Ankle Boot'}\n",
    "    \n",
    "utils.display_grid_data(dl, classes, ncols=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reinitialize the dataloader so we can read all the data, and get the data and labels into numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(mnist_train, batch_size=60000, num_workers=utils.get_num_cpus())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_data = None\n",
    "mnist_labels = None\n",
    "for batch, lab in dl:\n",
    "    mnist_data = batch.detach().numpy().squeeze()\n",
    "    mnist_labels = lab.detach().numpy()\n",
    "mnist_data = np.reshape(mnist_data, (60000, 28 * 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use umap to create the embedding.  Note that we use all the mnist training data here to create the embedding.  Subsampling the data before this step will cause us to get different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "standard_embedding = umap.UMAP(verbose=True).fit_transform(mnist_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the embedding in a non interactive plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='white', rc={'figure.figsize':(10,8)})\n",
    "plt.scatter(standard_embedding[:, 0], standard_embedding[:, 1], c=mnist_labels.astype(int), s=0.1, cmap='Spectral');\n",
    "plt.colorbar(boundaries=np.arange(11)-0.5).set_ticks(np.arange(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot is pretty busy.  Subsample the data to 10000 points so we can introspect it a little easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.choice(standard_embedding.shape[0], 10000, replace=False)\n",
    "reduced_embedding = standard_embedding[idx, :]\n",
    "reduced_data = mnist_data[idx, :]\n",
    "reduced_labels = mnist_labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(reduced_embedding[:, 0], reduced_embedding[:, 1], c=reduced_labels.astype(int), s=0.1, cmap='Spectral');\n",
    "plt.colorbar(boundaries=np.arange(11)-0.5).set_ticks(np.arange(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a pretty cool plot.  You can really see the separation of the classes in the MNIST dataset.  You can also see that there are some points in the clusters that don't belong.  But you know what would make this plot really rock?  Zoom, pan, and ability to see the images when we hover over a point.  The bokeh library to the rescue.  First, reshape the data back to an image rather than a flat vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_data = np.reshape(reduced_data, (10000, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "utils.plot_interactive_embedding(reduced_embedding,\n",
    "                                 reduced_data,\n",
    "                                 reduced_labels,\n",
    "                                 classes,\n",
    "                                 title='Fashion MNIST UMAP Embedding')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this is a lot nicer plot!  You will notice that as you hover your mouse over the points, the example images will pop up.  This allows you to see which cluster is which and it is helpful for analysis.  On the right hand side of the plot are the \"tools\" that bokeh offers.  You can toggle the tools on and off by clicking them once to enable, then again to disable.  To zoom in using the scroll wheel, click the \"Wheel Zoom\" tool to enable it.  To pan, enable the panning tool and then left click and drag to move the plot.\n",
    "\n",
    "Try zooming into one of the clusters and finding an example that doesn't belong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
