{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "`np.sctypes` was removed in the NumPy 2.0 release. Access dtypes explicitly instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mimgaug\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m augmenters \u001b[38;5;28;01mas\u001b[39;00m iaa\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/pylightning/venv/lib/python3.11/site-packages/imgaug/__init__.py:7\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m__future__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m absolute_import\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# this contains some deprecated classes/functions pointing to the new\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# classes/functions, hence always place the other imports below this so that\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# the deprecated stuff gets overwritten as much as possible\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mimgaug\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimgaug\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# pylint: disable=redefined-builtin\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mimgaug\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01maugmentables\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01maugmentables\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mimgaug\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01maugmentables\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/pylightning/venv/lib/python3.11/site-packages/imgaug/imgaug.py:45\u001b[39m\n\u001b[32m     36\u001b[39m DEFAULT_FONT_FP = os.path.join(\n\u001b[32m     37\u001b[39m     os.path.dirname(os.path.abspath(\u001b[34m__file__\u001b[39m)),\n\u001b[32m     38\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mDejaVuSans.ttf\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     39\u001b[39m )\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# to check if a dtype instance is among these dtypes, use e.g.\u001b[39;00m\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# `dtype.type in  NP_FLOAT_TYPES` do not just use `dtype in NP_FLOAT_TYPES` as\u001b[39;00m\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# that would fail\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m NP_FLOAT_TYPES = \u001b[38;5;28mset\u001b[39m(\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43msctypes\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mfloat\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     46\u001b[39m NP_INT_TYPES = \u001b[38;5;28mset\u001b[39m(np.sctypes[\u001b[33m\"\u001b[39m\u001b[33mint\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     47\u001b[39m NP_UINT_TYPES = \u001b[38;5;28mset\u001b[39m(np.sctypes[\u001b[33m\"\u001b[39m\u001b[33muint\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/pylightning/venv/lib/python3.11/site-packages/numpy/__init__.py:400\u001b[39m, in \u001b[36m__getattr__\u001b[39m\u001b[34m(attr)\u001b[39m\n\u001b[32m    397\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(__former_attrs__[attr], name=\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m __expired_attributes__:\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m    401\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m`np.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` was removed in the NumPy 2.0 release. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    402\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m__expired_attributes__[attr]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    403\u001b[39m         name=\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    404\u001b[39m     )\n\u001b[32m    406\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m attr == \u001b[33m\"\u001b[39m\u001b[33mchararray\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    407\u001b[39m     warnings.warn(\n\u001b[32m    408\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m`np.chararray` is deprecated and will be removed from \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    409\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mthe main namespace in the future. Use an array with a string \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    410\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mor bytes dtype instead.\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: `np.sctypes` was removed in the NumPy 2.0 release. Access dtypes explicitly instead."
     ]
    }
   ],
   "source": [
    "from imgaug import augmenters as iaa\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch import nn\n",
    "from pytorch_lightning import LightningModule\n",
    "\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import FashionMNIST\n",
    "import torchvision.transforms.functional as TF\n",
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim import Adam\n",
    "\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "\n",
    "import utils as utils\n",
    "\n",
    "DATA_DIR = './fashionMNIST/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomAugmentor:\n",
    "    \n",
    "    def __init__(self):\n",
    "            self.aug = iaa.Sequential([iaa.flip.Fliplr(p=0.5),\n",
    "                            iaa.flip.Flipud(p=0.5),\n",
    "                            iaa.GaussianBlur(sigma=(0.0, 0.1)),\n",
    "                           ])\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        img = np.array(img)\n",
    "        # Return a copy here to work around the error: ValueError: At least one stride \n",
    "        # in the given numpy array is negative, and tensors with negative strides \n",
    "        # are not currently supported.\n",
    "        return self.aug.augment_image(img).copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitMNIST(LightningModule):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # mnist images are (1, 28, 28) (channels, width, height)\n",
    "        self.layer_1 = torch.nn.Conv2d(1, 32, 3)\n",
    "        self.layer_2 = torch.nn.MaxPool2d(2)\n",
    "        self.layer_3 = torch.nn.Conv2d(32, 64, 3)\n",
    "        self.layer_4 = torch.nn.MaxPool2d(2)\n",
    "        self.layer_5 = torch.nn.Conv2d(64, 64, 3)\n",
    "        self.fc1 = torch.nn.Linear(64 * 3 * 3, 64)\n",
    "        self.fc2 = torch.nn.Linear(64, 10)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, channels, width, height = x.size()\n",
    "        \n",
    "        # (b, 1, 28, 28) -> (b, 1*28*28)\n",
    "        # x = x.view(batch_size, -1)\n",
    "        \n",
    "        # conv + relu\n",
    "        x = self.layer_1(x)\n",
    "        x = torch.relu(x)\n",
    "        \n",
    "        # maxpool\n",
    "        x = self.layer_2(x)\n",
    "        \n",
    "        # conv + relu\n",
    "        x = self.layer_3(x)\n",
    "        x = torch.relu(x)\n",
    "        \n",
    "        # maxpool\n",
    "        x = self.layer_4(x)\n",
    "        \n",
    "        # conv + relu\n",
    "        x = self.layer_5(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        # flatten\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        \n",
    "        # densely connected layers\n",
    "        x = self.fc1(x)\n",
    "        x = torch.relu(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        # probability distribution over labels\n",
    "        x = torch.log_softmax(x, dim=1)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def cross_entropy_loss(self, logits, labels):\n",
    "        return F.nll_loss(logits, labels)\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # transforms for images\n",
    "        transform=transforms.Compose([CustomAugmentor(),\n",
    "                                      transforms.ToTensor()])\n",
    "        fmnist_train = FashionMNIST(DATA_DIR, train=True, download=True, transform=transform)\n",
    "        self.fmnist_test = FashionMNIST(DATA_DIR, train=False, download=True, transform=transforms.ToTensor())\n",
    "        \n",
    "        self.fmnist_train, self.fmnist_val = random_split(fmnist_train, [55000, 5000])\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.fmnist_train, batch_size=64, num_workers=utils.get_num_cpus())\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.fmnist_val, batch_size=64, num_workers=utils.get_num_cpus())\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.fmnist_test, batch_size=64, num_workers=utils.get_num_cpus())\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return Adam(self.parameters(), lr=1e-3)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self.forward(x)\n",
    "        loss = self.cross_entropy_loss(logits, y)\n",
    "        \n",
    "        logs = {'train_loss': loss}\n",
    "        return {'loss': loss, 'log': logs}\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.cross_entropy_loss(logits, y)\n",
    "        return {'val_loss': loss}\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        tensorboard_logs = {'val_loss': avg_loss}\n",
    "        return {'val_loss': avg_loss, 'log': tensorboard_logs}\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.cross_entropy_loss(logits, y)\n",
    "        \n",
    "        return {'test_loss': loss}\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['test_loss'] for x in outputs]).mean()\n",
    "        tensorboard_logs = {'test_loss': avg_loss}\n",
    "        return {'test_loss': avg_loss, 'log': tensorboard_logs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = LitMNIST()\n",
    "x = torch.Tensor(1, 1, 28, 28)\n",
    "out = net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class map from the fashion mnist website https://github.com/zalandoresearch/fashion-mnist\n",
    "classes = {0: 'T-shirt/top',\n",
    "           1: 'Trouser',\n",
    "           2: 'Pullover',\n",
    "           3: 'Dress',\n",
    "           4: 'Coat',\n",
    "           5: 'Sandal',\n",
    "           6: 'Shirt',\n",
    "           7: 'Sneaker',\n",
    "           8: 'Bag',\n",
    "           9: 'Ankle Boot'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = net.train_dataloader()\n",
    "utils.display_grid_data(dl, classes, ncols=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup lightning for reproducability between runs.  That way we can\n",
    "# make tweaks and see what the effect on performance is.  If we don't set this we will\n",
    "# get different accuracy results between runs, and will complicate measuring the effect\n",
    "# of our changes on the performance.  We also have to setup the trainer for deterministic\n",
    "# runs as well (below)\n",
    "\n",
    "seed_val = 42\n",
    "seed_everything(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = 0\n",
    "if torch.cuda.is_available():\n",
    "    gpus = torch.cuda.device_count()\n",
    "print(f'Number of GPUs available: {gpus}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LitMNIST()\n",
    "# Set the trainer for deterministic runs.\n",
    "trainer = Trainer(max_epochs=3, deterministic=True, gpus=gpus)\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter('./lightning_logs')\n",
    "model = model.to('cpu')\n",
    "writer.add_graph(model, torch.Tensor(1, 1, 28, 28))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from torchviz import make_dot\n",
    "#out = model(torch.Tensor(1, 1, 28, 28))\n",
    "#make_dot(out)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[module for module in model.modules() if type(module) != nn.Sequential]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = model.test_dataloader()\n",
    "model = model.to('cpu')\n",
    "labels, predictions = utils.model_predictions(dl, model)\n",
    "df, acc = utils.measure_accuracy(labels, predictions, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
